{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data/EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/train.csv')#,index_col=0)\n",
    "test = pd.read_csv('../datasets/test.csv')#, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noval(col):\n",
    "    print((col).isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noval(train['Lot Frontage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Lot Frontage'].fillna(0, inplace=True)\n",
    "#filling NA's in this numerical column with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noval(train['Lot Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Alley'].fillna('No Access', inplace=True)\n",
    "train['Alley'].value_counts()\n",
    "#data description states \"NA\" values indicate no alley access, so I replace those blanks with \"No Access\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Condition 2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Conditions']= train['Condition 1'].str.cat(train['Condition 2'], sep=\",\")\n",
    "#Condition 1 and Condition 2 deal with the same values; I combined into one column (separating vals with a comma) for ease/to prevent future high multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Condition 1', 'Condition 2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noval(train['Mas Vnr Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noval(train['Mas Vnr Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure the 22 null rows match up with respective columns;\n",
    "#rather than get rid of them, I'll replace them with relevant assumed values\n",
    "(train[train['Mas Vnr Type'].isnull()]).index & (train[train['Mas Vnr Area'].isnull()]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Mas Vnr Type'].fillna('None', inplace=True)\n",
    "train['Mas Vnr Area'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[train['Bsmt Cond'].isnull()].index) & (train[train['Bsmt Qual'].isnull()].index) & (train[train['Bsmt Exposure'].isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are more null vals in 'Bsmt Exposure'\n",
    "#after identifying indexes that do not match; replacing those appropriately\n",
    "(train[train['Bsmt Exposure'].isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[1997, 'Bsmt Exposure']='No'\n",
    "train.loc[1547, 'Bsmt Exposure']='No'\n",
    "train.loc[1456, 'Bsmt Exposure']='No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'NB' for no basement\n",
    "train['Bsmt Qual'].fillna('NB', inplace=True)\n",
    "train['Bsmt Cond'].fillna('NB', inplace=True)\n",
    "train['Bsmt Exposure'].fillna('NB', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BsmtFin Type 1'].fillna('NB', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BsmtFin SF 1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BsmtFin Type 2'].fillna('NB', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BsmtFin SF 2'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Bsmt Unf SF'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BsmtFin SF'] = train['BsmtFin SF 1'] + train['BsmtFin SF 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename to match pattern of other basement names/easier to call\n",
    "train.rename(columns ={'Total Bsmt SF': 'Bsmt Total SF'}, inplace=True)\n",
    "train['Bsmt Total SF'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Bsmt Full Bath'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Bsmt Half Bath'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Bsmt Half Bath'].fillna(0, inplace=True)\n",
    "train['Bsmt Full Bath'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Bsmt Total Baths'] = train['Bsmt Full Bath'] + train['Bsmt Half Bath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Bsmt Full Bath',axis=1, inplace=True)\n",
    "train.drop('Bsmt Half Bath', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Total Baths'] = train['Full Bath'] + train['Half Bath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another instance where data descr uses NA to mean no\n",
    "train['Fireplace Qu'].fillna('NFP', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fireplaces*Fireplace Quality '] = train['Fireplaces']*train['Fireplace Qu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Fireplaces',axis=1,inplace=True)\n",
    "train.drop('Fireplace Qu', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Na = no garage\n",
    "train['Garage Type'].fillna('NG',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Garage Yr Blt'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Garage Finish'].fillna('NG',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Garage Cars'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The null value in 'garage cars' corresponds to a instance where 'garage type' is full but other garage variables are also empty\n",
    "#Therefore, I am dropping the row\n",
    "train.drop(train.index[1712], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Garage Qual'].fillna('NG', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Garage Cond'].fillna('NG', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAs in 'Pool Qual' correspond with 0's in Pool sq ft; therefore, filling as 'NP', no pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Pool QC'].fillna('NP', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fence'].fillna('NF', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Misc Feature'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Mo/Yr Sold']= (train['Mo Sold'].map(str)).str.cat((train['Yr Sold'].map(str)), sep=\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Mo Sold', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[1699]['Garage Yr Blt']\n",
    "#Garage could not have been built in a year that has yet to occur; removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([1699], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an interaction term of these two closely related variables\n",
    "train['Overall Quality Score'] = train['Overall Qual']*train['Overall Cond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Exterior Covering'] = (train['Exterior 1st']).str.cat((train['Exterior 2nd']), sep='&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Exterior Quality Score'] = (train['Exter Qual'].replace(['Ex', 'Gd','TA','Fa','Po'], [5,4,3,2,1]))*(train['Exter Cond'].replace(['Ex', 'Gd','TA','Fa','Po'], [5,4,3,2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Exter Qual', axis=1, inplace=True)\n",
    "train.drop('Exter Cond', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BsmtFin Quality Score'] = (train['BsmtFin Type 1'].replace(['GLQ','ALQ','BLQ','Rec','LwQ', 'Unf','NB'],[6,5,4,3,2,1,0]))*(train['BsmtFin Type 2'].replace(['GLQ','ALQ','BLQ','Rec','LwQ', 'Unf','NB'],[6,5,4,3,2,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('BsmtFin Type 1', axis=1,inplace=True)\n",
    "train.drop('BsmtFin Type 2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots to identify correlations and outliers & decide on course of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (16,16))\n",
    "sns.heatmap(train.corr(),cmap='RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap((train.corr()[['SalePrice']]).sort_values('SalePrice', ascending=False), annot=True) #sourced from code written by Mahdi S.\n",
    "plt.title('Sale Price Correlations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above heatmaps, we can see which variables are most closely correlated with sale price and each other:\n",
    "                                 * Overall Quality\n",
    "                                 * Gr Liv Area (Above Ground Living Area SF)\n",
    "                                 * Garage Cars/Garage Area\n",
    "                                 * 1st Fl SF\n",
    "                                 * Bsmt Total SF\n",
    "                                 * Full Baths\n",
    "\n",
    "With this information, I can identify other variables correlated with these to expand/play around with the variables of my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(train['Overall Qual'])\n",
    "plt.title('Overall Quality Rankings', size=15)\n",
    "plt.xlabel('Overall Quality Ranking');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clear outliers here are properties with overall quality values below 2. <br>\n",
    "There are only 4 instances of these super low scores. <br> Therefore, I think it is prudent to remove these as they may unnecessarily skew my model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Overall Qual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Overall Qual'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train['Gr Liv Area'])\n",
    "plt.title('Above Ground Living Area', size=15)\n",
    "plt.xlabel('Above Ground Living Area (SqFt)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train['Gr Liv Area']>=3000).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homes with an above ground living area square footage of over 3000sqft represent less than 1% of all homes. <br>\n",
    "Rather than remove them, I will create a separate column for these 'larger area' homes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Larger Gr Liv Area'] = ((train['Gr Liv Area']>=3000)==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train['Garage Cars'])\n",
    "plt.title('Car Capacity of Garage', size=15)\n",
    "plt.xlabel('Number of Cars');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clear outliers here are garages with car capacities of 4 & 5. <br> There is only 1 garage that accomodates 5 cars, and it does not fall into the 'Larger Gr Living Area' column (as would be expected as ground living area sqft and garage car capacities are otherwise correlated columns). <br> \n",
    "We can conclude it is an anomaly and not of benefit to my models. It will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Garage Cars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Garage Cars'] != 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train['Garage Area'])\n",
    "plt.title('Garage Area (SqFt)')\n",
    "plt.xlabel('Garage Area (SqFt)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homes with garage areas over 1000 SqFt are rare, and only 1 contains a garage over 1400, an anomaly. <br> I will drop this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train['Garage Area']>1000).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[train['Garage Area']>1400]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([960],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the clear relationship between the 'Garage Area' & 'Garage Cars' columns, I will create an interaction term of the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train['1st Flr SF'])\n",
    "plt.title('1st Floor Total SqFt', size=15)\n",
    "plt.xlabel('Square Feet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these outlier home sizes, there is only one home with a square footage over 5000 , one home with a square footage over 4000 , and one with a square footage over 3000. <br> These I will remove from my dataset. <br>The homes with square footage over 2000 mostly also appear in the variable 'Larger Gr Liv Area' I created to represent homes with an overall sqft living area over the max 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train['1st Flr SF']>2000).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train[(train['1st Flr SF']>2000) & (train['Larger Gr Liv Area']==True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['1st Flr SF'] <3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train['2nd Flr SF'])\n",
    "plt.title('2nd Floor Total SqFt', size=15)\n",
    "plt.xlabel('Square Feet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 outliers here. Homes whose second floor square footage exceeds 1800. Because these 3 match up with homes in my category for larger than avg above ground living area, I will keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train['2nd Flr SF']>1800).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[(train['2nd Flr SF']>1800) & (train['Larger Gr Liv Area']==True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train['Bsmt Total SF'])\n",
    "plt.title('Total Basement Area (Finished&Unfinished)', size=15)\n",
    "plt.xlabel('Square Feet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 2 houses wherein the total SF of the basement is greater than 3000. <br>\n",
    "I am creating a new column that uses 1 to denote if a house's finished square footage is greater than half of the total basement square footage (0 if not). <br>\n",
    "My assumption is that because total basement sq footage is positively correlated with sale price, the larger the basement, the more the house is worth; the more finished square footage of the basement, the higher the sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LgFin = []\n",
    "for index, row in train.iterrows():\n",
    "    if (row['BsmtFin SF 1']+ row['BsmtFin SF 2'])>(row['Bsmt Total SF']/2):\n",
    "        LgFin.append(1)\n",
    "    else:\n",
    "        LgFin.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Over 50%Fin Bsmt'] = LgFin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BsmtFin SF'] = train['BsmtFin SF 1'] + train['BsmtFin SF 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['PID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.boxplot(train['Fence'], train['SalePrice'])\n",
    "flabels = ['No Fence', 'Minimum Wood/Wire','Good Wood','Minimum Privacy','Good Privacy']\n",
    "g.set_xticklabels(flabels,rotation=45)\n",
    "plt.title('Fence Type Rating', size=15)\n",
    "plt.xlabel('Fence Type');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because I would like to use fence - or at least determine if it is worth using - in my model, I am converting the categ. values into numbers\n",
    "train['Fence'] = train['Fence'].replace(['NF','MnWw','GdWo','MnPrv','GdPrv'], [0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My instinct is that, as with most places, neighborhood is a large factor in determining the value/\"sell-ability\" of a home. <br> Let's check this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "g = sns.pointplot(x=train['Neighborhood'], y=train['SalePrice'], data=train, color='red')\n",
    "labels=['Sawyer','Sawyer West',\n",
    "        'North Ames',\n",
    "        'Timberland',\n",
    "        'Edwards', \n",
    "        'Old Town', \n",
    "        'Briardale',\n",
    "        'College Creek', \n",
    "        'Somerset',\n",
    "        'Mitchell',\n",
    "        'Stonebrook',\n",
    "        'Northridge Heights',\n",
    "        'Gilbert',\n",
    "        'Crawford',\n",
    "        'Iowa DOT & Railroad',\n",
    "        'Northwest Ames',\n",
    "        'Veenker',\n",
    "        'Meadow Village',\n",
    "        'S&W Iowa State U',\n",
    "        'Northridge',\n",
    "        'Clear Creek', \n",
    "        'Bloomington Heights', \n",
    "        'Brookside', \n",
    "        'Northpark Villa', \n",
    "        'Bluestem', \n",
    "        'Green Hills', \n",
    "        'Greens', \n",
    "        'Landmark']\n",
    "g.set_xticklabels(labels,rotation=70)\n",
    "plt.title('Sale Price by Neighborhood', size=15)\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.xlabel('Neighborhood')\n",
    "mean= train['SalePrice'].mean()\n",
    "plt.axhline(mean, color='green', linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows sale price of homes by the neighborhood in which they are located. The green line represents the average price of a home sold in Ames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.pivot_table(train, index=['Neighborhood'], values=['SalePrice'], columns = ['Yr Sold']).plot(kind='bar', width = .9, figsize=(14,10))\n",
    "ax.set_xlabel('Neighborhood')\n",
    "ax.set_title('Prices of Homes Sold in Ames Neighborhoods by Year', fontsize=15)\n",
    "ax.legend(labels=['2006','2007','2008','2009','2010']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the price of homes sold by neighborhood for each year the data is available.<br> \n",
    "Below, the number of homes sold by neighborhood for each year the data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.pivot_table(train, index=['Neighborhood'], values=['SalePrice'], columns = ['Yr Sold'], aggfunc=[len]).plot(kind='bar', figsize=(14,10))\n",
    "ax.set_xlabel('Neighborhood')\n",
    "ax.set_title('Number of Homes Sold in Ames Neighborhoods by Year', fontsize=15)\n",
    "ax.legend(labels=['2006','2007','2008','2009','2010']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While more homes were sold in the North Ames neighborhood, they were not necessarily the highest sale prices. <br> The Northridge, Northridge Heights, Green Hills, and Stonebrook neighborhoods had the highest priced homes sold.<br>\n",
    "Aside: Home sales in Green Hills were conspicuously low/absent for years after 2007 (recall the recession hit in 2008)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My interest in this variable has been piqued. In order to use it in my Linear Regression model, I am going to convert the data in numerical dummy columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(train['Neighborhood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, dummies], axis=1)\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Neighborhood', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving my cleaned data to a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../datasets/cleaned_training_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A revised sale price corr heatmap with my cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(13,20))\n",
    "sns.heatmap((train.corr()[['SalePrice']]).sort_values('SalePrice', ascending=False), annot=True)\n",
    "plt.title('Sale Price Correlations', size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A revised total heatmap with my cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (16,16))\n",
    "sns.heatmap(train.corr(),cmap='RdBu');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this neighborhood transformation has added 28 new variables to my list of possible features, this only prompts more selectivity in what other variables will be used in my analysis modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will run when I have more time; takes forever\n",
    "#sns.pairplot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(train['Overall Qual'], train['SalePrice'] , color='#E84855')\n",
    "plt.ylabel('Sale Price (USD)')\n",
    "plt.xlabel('Overall Quality (1-10)')\n",
    "plt.title('Sale Price by Home Quality Rating', size=15)\n",
    "mean = train['Overall Qual'].mean()\n",
    "smean = train['SalePrice'].mean()\n",
    "plt.axvline(mean, color='black', linestyle='--')\n",
    "plt.axhline(smean, color = 'green', linestyle='--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(train['Overall Quality Score'], train['SalePrice'] , color='#2B3A67')\n",
    "plt.ylabel('Sale Price (USD)')\n",
    "plt.xlabel('Home Quality + Condition Score')\n",
    "plt.title('Sale Price by Quality Score')\n",
    "mean = train['Overall Quality Score'].mean()\n",
    "smean = train['SalePrice'].mean()\n",
    "plt.axhline(smean, color = 'green', linestyle='--')\n",
    "plt.axvline(mean, color='red', linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "### After cleaning my data and performing the necessary functions on variables, I am ready to begin creating and testing out a few models.\n",
    "\n",
    "### I have chosen to:\n",
    "                    * combine columns with similar or highly related variables\n",
    "                    * eliminate outliers that appeared in quantities under 10\n",
    "                    * keep outliers that appeared in quantities over 10 because eliminating too many outliers may cause one or multiple iterations of my model to be overfit later on\n",
    "                    * create new columns for outlier variables I think will be significant in determining my target later\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reordering so that my target column is the last one in my dataframe\n",
    "\n",
    "#cols = list(train.columns.values)\n",
    "#cols.pop(cols.index('SalePrice')) \n",
    "#train = train[cols+['SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def scatterem(df, y):\n",
    "    #for col in range (0,3):\n",
    "        #fig, axs = plt.subplots()\n",
    "        #axs.scatter(df.iloc[:,col],y)\n",
    "    #return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterem(train, train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SalePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.hist(train['SalePrice'], color = '#9BD1E5')\n",
    "plt.title('Sale Price Distribution', size=15)\n",
    "plt.xlabel('Sale Price (USD)')\n",
    "plt.xlabel('Frequency')\n",
    "plt.axvline((train['SalePrice'].mean()), color='red', linestyle='--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.distplot(train['SalePrice'], color='#8EF9F3', kde_kws={\"color\": \"purple\"})\n",
    "ax.set_xlabel('Sale Price (USD)')\n",
    "ax.set_title('Sale Price Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "#### Feature Selection:\n",
    "Considering my train dataset still contains 82 variables, utilizing all of them will make my model severely prone to overfitting.<br> My initial model will utilize a fraction of these, allowing for more precise tuning in later versions.\n",
    "\n",
    "#### Feature Engineering\n",
    "Before instantiating/fitting models, I will utilize scikit-learn's Train Test Split and Standard Scaler methods to prepare my data. <br>\n",
    "Based on my [second heat map](#A-revised-total-heatmap-with-my-cleaned-data), the correlations between my independent variables were not so high that I felt there was significant multicollinearity to justify using scikit learn's Polynomial Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ends = train[['Overall Quality Score', 'Year Built', 'Gr Liv Area','BsmtFin SF','Garage Area','Fence', 'Larger Gr Liv Area', 'Over 50%Fin Bsmt']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Overall Quality Score', 'Year Built', 'Gr Liv Area', 'BsmtFin SF','Garage Area','Fence','Larger Gr Liv Area', 'Over 50%Fin Bsmt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, ends], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = train.iloc[:,72:108]\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(train, x_vars =X1,y_vars=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y_train, y_test = train_test_split(X1,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss= StandardScaler()\n",
    "X1_train_sc = ss.fit_transform(X1_train)\n",
    "X1_test_sc = ss.transform(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally.... Modeling\n",
    "\n",
    "### I will be using 3 types of models:\n",
    "\n",
    "#### Linear Regression\n",
    "\n",
    "#### Ridge Regression\n",
    "\n",
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate and fit model\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X1_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores = cross_val_score(lr, X1_train_sc, y_train, cv=3)\n",
    "lr_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeCV(alphas=np.linspace(.1, 10, 10))\n",
    "\n",
    "ridge.fit(X1_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores = cross_val_score(ridge, X1_train_sc, y_train, cv=3)\n",
    "ridge_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(n_alphas=10)\n",
    "\n",
    "lasso.fit(X1_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores = cross_val_score(lasso, X1_train_sc, y_train, cv=3)\n",
    "lasso_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso seems to be performing the best, so I will stick with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lasso.predict(X1_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(preds, residuals, c=preds)\n",
    "plt.title('Residual Distribution', size=15)\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Residual')\n",
    "plt.axhline(0, color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(y_test,preds, c=preds)\n",
    "plt.title('Actual V. Predicted', size=15)\n",
    "plt.xlabel('Actual Price (USD)')\n",
    "plt.ylabel('Predicted Price (USD)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef = pd.Series(lasso.coef_, index = X1_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef.plot(kind = \"barh\", color='violet', figsize=(8,16))\n",
    "plt.title(\"Coefficients in the Lasso Model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart shows the coefficients of my chosen variables in my lasso model.\n",
    "This allows me to determine what variables are most important to determining value of a home; those that add value, and those that cause a decline.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
